
# Release Notes worksheet inductor

The main goal of this process is to rephrase all the commit messages below to make them **clear and easy to read** by the end user. You should follow the following instructions to do so:

* **Please clean up and format commit titles to be readable by the general PyTorch user.** Make sure you're [following the guidance here](https://docs.google.com/document/d/14OmgGBr1w6gl1VO47GGGdwrIaUNr92DFhQbY_NEk8mQ/edit)! Your resulting notes must be consistent and easy to read.
* Please sort commits into the following categories (you should not rename the categories!), I tried to pre-sort these to ease your work, feel free to move commits around if the current categorization is not good.
* Anything that is not public facing needs to be removed.
* If anything is miscategorized/belongs to another domain, move it to `miscategorized.md`.
* Please scan through `miscategorized.md` and handle any commits that belong within your domain according to these instructions.
* We place a lot of emphasis on the “BC-breaking” and “deprecation” sections. Those should be where the most effort goes in. The “improvements” and “bug fixes” for Python API should be nice as well.
* Once you are finished, move this very file from `todo/` to `done/` and submit a pull request.

The categories below are as follows:

* BC breaking: All commits that are BC-breaking. These are the most important commits. If any pre-sorted commit is actually BC-breaking, do move it to this section. Each commit should contain a paragraph explaining the rational behind the change as well as an example for how to update user code [BC-Guidelines](https://docs.google.com/document/d/14OmgGBr1w6gl1VO47GGGdwrIaUNr92DFhQbY_NEk8mQ/edit#heading=h.a9htwgvvec1m).
* Deprecations: All commits introducing deprecation. Each commit should include a small example explaining what should be done to update user code.
* new_features: All commits introducing a new feature (new functions, new submodule, new supported platform etc)
* improvements: All commits providing improvements to existing feature should be here (new backend for a function, new argument, better numerical stability)
* bug fixes: All commits that fix bugs and behaviors that do not match the documentation
* performance: All commits that are added mainly for performance (we separate this from improvements above to make it easier for users to look for it)
* documentation: All commits that add/update documentation
* Developers: All commits that are not end-user facing but still impact people that compile from source, develop into pytorch, extend pytorch, etc
* not user facing: All commits that are not public end-user facing and hence should be dropped from the release notes

## inductor
### bc breaking
### deprecation
### new features
- Allow user to pass in custom partitioner function ([#157580](https://github.com/pytorch/pytorch/pull/157580))
### improvements
- Add Inductor support for MTIA backend ([#159211](https://github.com/pytorch/pytorch/pull/159211))
### bug fixes
- Fix wrong meta function for `constant_pad_nd` ([#159878](https://github.com/pytorch/pytorch/pull/159878))
- Fix learnable bias assertion error in inductor ([#161170](https://github.com/pytorch/pytorch/pull/161170))
- Fix int64 from `MutationOutput` Buffer ([#162020](https://github.com/pytorch/pytorch/pull/162020))
- Fix inductor cuda sort `nan` behavior ([#159308](https://github.com/pytorch/pytorch/pull/159308))
- Fix layout for local buf in outer loop fusion ([#160857](https://github.com/pytorch/pytorch/pull/160857))
- Fix slice scatter `dtype` consistency ([#160851](https://github.com/pytorch/pytorch/pull/160851))
- Fix 3d tiled online softmax ([#162341](https://github.com/pytorch/pytorch/pull/162341))
### performance
- Improve performance of A16W4 and A16W8 `GEMM` template ([#159127](https://github.com/pytorch/pytorch/pull/159127)) ([#161148](https://github.com/pytorch/pytorch/pull/161148))
- More aggressive persistent reduction ([#161055](https://github.com/pytorch/pytorch/pull/161055))
- Add a few outer dimension reduction cases for LOAF ([#162028](https://github.com/pytorch/pytorch/pull/162028))
- Fuse two RoPE kernels into a single kernel and improving runtime efficiency ([#161420](https://github.com/pytorch/pytorch/pull/161420))
### docs
- Add documentation for CUDAGraph partition ([#159450](https://github.com/pytorch/pytorch/pull/159450))
### devs
- Deprecated `allow_tf32` in `tl.dot(..., allow_tf32=...)`, use `tl.dot(..., input_precision=...)` ([#160711](https://github.com/pytorch/pytorch/pull/160711))
- Log autotune choices and benchmark result to scuba/chrome trace ([#159496](https://github.com/pytorch/pytorch/pull/159496))
- Add TLParse artifact for logging runtime of collective and compute ops ([#159730](https://github.com/pytorch/pytorch/pull/159730))
- Call `jit_post_compile_hook` within Inductor Triton Kernel compile path ([#161443](https://github.com/pytorch/pytorch/pull/161443))
- Prune configs that require more shared memory than the hardware limit. ([#161996](https://github.com/pytorch/pytorch/pull/161996))
- Runtime estimations using nccl estimator on mm only benchmark mode ([#161405](https://github.com/pytorch/pytorch/pull/161405))
- Don't use torch.backends.cuda.matmul.allow_tf32 in inductor cache key ([#159480](https://github.com/pytorch/pytorch/pull/159480))
### not user facing
- Add log for graph partition reasons (CUDAGraph) ([#159425](https://github.com/pytorch/pytorch/pull/159425))
- Eliminate workspace info in templates with new API ([#159055](https://github.com/pytorch/pytorch/pull/159055))
- Add user annotation for FX graph cache key ([#159318](https://github.com/pytorch/pytorch/pull/159318))
- Restructure flex attention kernel into flex subdirectory ([#159437](https://github.com/pytorch/pytorch/pull/159437))
- Check addmm dtypes ([#159509](https://github.com/pytorch/pytorch/pull/159509))
- Fix an incorrect descriptor ([#159407](https://github.com/pytorch/pytorch/pull/159407))
- Record a pt2_compile_event for combo kernels ([#159306](https://github.com/pytorch/pytorch/pull/159306))
- fix open temp file failed on Windows. ([#159342](https://github.com/pytorch/pytorch/pull/159342))
- Fix set_linter's handling of f-strings for Python 3.12 and up (fix #159056) ([#159252](https://github.com/pytorch/pytorch/pull/159252))
- Add lowering for repeat_interleave.Tensor with output size specified (#147160) ([#158462](https://github.com/pytorch/pytorch/pull/158462))
- Fix grouped MM load along K when TMA loads are not used ([#159485](https://github.com/pytorch/pytorch/pull/159485))
- Remove dynamo_timed from the CachingAutotuner.coordinate_descent_tuning() hot path. ([#159588](https://github.com/pytorch/pytorch/pull/159588))
- Use max of input/output size for bucketing ([#159717](https://github.com/pytorch/pytorch/pull/159717))
- Reduce CPU overhead for reduce_scatter_merge_fn_to_trace ([#159723](https://github.com/pytorch/pytorch/pull/159723))
- Fix warnings in triton_helpers.py ([#159719](https://github.com/pytorch/pytorch/pull/159719))
- Fix detection of magic number placeholder in inductor ([#157784](https://github.com/pytorch/pytorch/pull/157784))
- Constrain OrderedSet generic to be Hashable ([#159684](https://github.com/pytorch/pytorch/pull/159684))
- Use writable temp file on windows ([#159738](https://github.com/pytorch/pytorch/pull/159738))
- Revert "add lowering for repeat_interleave.Tensor with output size specified" ([#159798](https://github.com/pytorch/pytorch/pull/159798))
- DeviceCopy should have the same layout as input ([#159615](https://github.com/pytorch/pytorch/pull/159615))
- Add cascade sum support for Inductor CPP backend ([#156296](https://github.com/pytorch/pytorch/pull/156296))
- Revert mtia interface  to avoid internal test failures ([#159809](https://github.com/pytorch/pytorch/pull/159809))
- Extract some HOP utils to be importable ([#159705](https://github.com/pytorch/pytorch/pull/159705))
- Wire in pt2_triton_builds ([#159897](https://github.com/pytorch/pytorch/pull/159897))
- Aadd _get_inductor_debug_symbol_cflags for debug symbol control. ([#159938](https://github.com/pytorch/pytorch/pull/159938))
- Fixup scaled_mm autotune ([#159948](https://github.com/pytorch/pytorch/pull/159948))
- Remove unnecessary `# noqa: set_linter` comments ([#159467](https://github.com/pytorch/pytorch/pull/159467))
- Fix test_dynamo_timed on Windows. ([#159981](https://github.com/pytorch/pytorch/pull/159981))
- Unification for inductor debug symbols ([#159998](https://github.com/pytorch/pytorch/pull/159998))
- Disable flex decoding on Windows. ([#160072](https://github.com/pytorch/pytorch/pull/160072))
- Log max_autotune exceptions ([#159688](https://github.com/pytorch/pytorch/pull/159688))
- Do not treat ReinterpretView as a realized node ([#159920](https://github.com/pytorch/pytorch/pull/159920))
- Fix CompiledArtifact.load path on Windows. ([#160268](https://github.com/pytorch/pytorch/pull/160268))
- Slow test some Windows UTs. ([#160267](https://github.com/pytorch/pytorch/pull/160267))
- Add back the revert part of mtia interface ([#160054](https://github.com/pytorch/pytorch/pull/160054))
- Fix some windows inductor UTs ([#160292](https://github.com/pytorch/pytorch/pull/160292))
- Normalize_path_separator for test_different_file_paths_local_pgo ([#160286](https://github.com/pytorch/pytorch/pull/160286))
- Fix collective schedule logging and runtime tests ([#160260](https://github.com/pytorch/pytorch/pull/160260))
- Fix test_different_file_paths_local_pgo on Windows. ([#160382](https://github.com/pytorch/pytorch/pull/160382))
- Fix triton bucketize mask propagation ([#159961](https://github.com/pytorch/pytorch/pull/159961))
- Save attributes for CppCompileError for pickleing ([#160294](https://github.com/pytorch/pytorch/pull/160294))
- Fix get_free_symbol_uses for several nodes ([#160314](https://github.com/pytorch/pytorch/pull/160314))
- Do not rpath CUDA stubs folder in JIT generated code ([#160179](https://github.com/pytorch/pytorch/pull/160179))
- Change IR node's stack trace to be computed lazily ([#160487](https://github.com/pytorch/pytorch/pull/160487))
- Pass backend parameter into GPU vertical pass file and pattern matcher ([#160404](https://github.com/pytorch/pytorch/pull/160404))
- Add lowering for repeat_interleave.Tensor with output size specified ([#158462](https://github.com/pytorch/pytorch/pull/158462))
- Fix dictionary iteration error ([#160552](https://github.com/pytorch/pytorch/pull/160552))
- Add assertion msg to sym_size and sym_stride ([#160591](https://github.com/pytorch/pytorch/pull/160591))
- Typo correction in variable name uninitalized_val in resize() function ([#160636](https://github.com/pytorch/pytorch/pull/160636))
- Allow indexing a flexible layout for extract_input_node_reduction_ranges ([#160645](https://github.com/pytorch/pytorch/pull/160645))
- Apply feedback to Enable padded stride support ([#160614](https://github.com/pytorch/pytorch/pull/160614))
- Raise exception in case of errors in memory reordering ([#160455](https://github.com/pytorch/pytorch/pull/160455))
- Fix propagating  torch.utils._sympy.functions.Identity in IndexPropagation ([#155504](https://github.com/pytorch/pytorch/pull/155504))
- Change IR node's stack traces to return a set of stack traces only ([#160701](https://github.com/pytorch/pytorch/pull/160701))
- Improve the readability of output handling ([#160374](https://github.com/pytorch/pytorch/pull/160374))
- Add TORCH_GUARD_OR_FALSE for cat ops ([#160250](https://github.com/pytorch/pytorch/pull/160250))
- Add kernel stack traces tlparse dump (#160608) ([#160779](https://github.com/pytorch/pytorch/pull/160779))
- Add correct name for CFF in tlparse ([#160599](https://github.com/pytorch/pytorch/pull/160599))
- Add cutedsl template support to compile ([#160108](https://github.com/pytorch/pytorch/pull/160108))
- Add signpost to provenance tracking error ([#160755](https://github.com/pytorch/pytorch/pull/160755))
- Fix crash on bmm when input is used twice. ([#160087](https://github.com/pytorch/pytorch/pull/160087))
- Fix duplicated kernel name in kernel stack trace tracking ([#160905](https://github.com/pytorch/pytorch/pull/160905))
- Fix aliased inputs by cloning ([#160668](https://github.com/pytorch/pytorch/pull/160668))
- Make Inductor benchmarker more compatible with Triton do_bench ([#160921](https://github.com/pytorch/pytorch/pull/160921))
- Propagate shapes in CSEVariable ([#152198](https://github.com/pytorch/pytorch/pull/152198))
- Preserve node meta to fix inductor generated kernel name for pattern matched graphs ([#160542](https://github.com/pytorch/pytorch/pull/160542))
- Add tlparse artifact for joint graph passes (for inference & non-freezing only) ([#160589](https://github.com/pytorch/pytorch/pull/160589))
- Fix old TMA API in persistent matmul template ([#161030](https://github.com/pytorch/pytorch/pull/161030))
- Fix descriptor broadcasting for singleton dimensions ([#160310](https://github.com/pytorch/pytorch/pull/160310))
- Allow exposing more functions during initial template expansion ([#159554](https://github.com/pytorch/pytorch/pull/159554))
- Fix tma issue ([#161025](https://github.com/pytorch/pytorch/pull/161025))
- Add level zero for xpu ([#161061](https://github.com/pytorch/pytorch/pull/161061))
- Enable updated __cplusplus macro ([#161064](https://github.com/pytorch/pytorch/pull/161064))
- TritonKernel.inductor_meta_common() -> self.inductor_meta_common() ([#160895](https://github.com/pytorch/pytorch/pull/160895))
- Disable min/max macro on Windows. ([#161133](https://github.com/pytorch/pytorch/pull/161133))
- Add libraries_dirs for level_zero ([#161146](https://github.com/pytorch/pytorch/pull/161146))
- Thread graphsafe rng input states for hops ([#160713](https://github.com/pytorch/pytorch/pull/160713))
- Forward fix of #152198 ([#161166](https://github.com/pytorch/pytorch/pull/161166))
- Avoid making node a successor/predecessor of itself ([#161205](https://github.com/pytorch/pytorch/pull/161205))
- Fix double-offset issue in `GEMM_TEMPLATE` ([#159233](https://github.com/pytorch/pytorch/pull/159233))
- Enable max compatible to msvc for oneAPI headers. ([#161196](https://github.com/pytorch/pytorch/pull/161196))
- Remove Windows unsupported build options. ([#161197](https://github.com/pytorch/pytorch/pull/161197))
- Add get page_size support for Windows. ([#161273](https://github.com/pytorch/pytorch/pull/161273))
- Fix march=native pass to Windows CC. ([#161264](https://github.com/pytorch/pytorch/pull/161264))
- Add MSVC language pack check. ([#161298](https://github.com/pytorch/pytorch/pull/161298))
- Improve pattern matching error msg ([#161423](https://github.com/pytorch/pytorch/pull/161423))
- Fix inductor complex float issue ([#160736](https://github.com/pytorch/pytorch/pull/160736))
- Fix SCALING_ROWWISE misclassification for scalar scales ([#160450](https://github.com/pytorch/pytorch/pull/160450))
- Log the specific triton kernel that fails ([#161452](https://github.com/pytorch/pytorch/pull/161452))
- Fix the wait method to actually wait ([#161561](https://github.com/pytorch/pytorch/pull/161561))
- Improve Scheduler init duration ([#161491](https://github.com/pytorch/pytorch/pull/161491))
- Select Algorithm clear feedback savers ([#161654](https://github.com/pytorch/pytorch/pull/161654))
- Fix Windows test case failure. ([#161497](https://github.com/pytorch/pytorch/pull/161497))
- Don't append None to choices in select algorithm ([#161672](https://github.com/pytorch/pytorch/pull/161672))
- Restructure decompose k ([#161026](https://github.com/pytorch/pytorch/pull/161026))
- Move template heuristics into dir ([#161097](https://github.com/pytorch/pytorch/pull/161097))
- Make Decompose-k  part of template heuristics ([#161098](https://github.com/pytorch/pytorch/pull/161098))
- Fix float16 default config 128 headdim ([#161647](https://github.com/pytorch/pytorch/pull/161647))
- Replace "and" with "logical_and" in bucketize_binary_search ([#160941](https://github.com/pytorch/pytorch/pull/160941))
- Fix SubgraphInfo round trip ([#161779](https://github.com/pytorch/pytorch/pull/161779))
- Remove offset check for while_loop ([#160669](https://github.com/pytorch/pytorch/pull/160669))
- Avoid aliasing when body_fn never executes ([#160670](https://github.com/pytorch/pytorch/pull/160670))
- Lift fw_compiler and bw_compiler as toplevel functions. ([#161762](https://github.com/pytorch/pytorch/pull/161762))
- Missing heuristic is not an error anymore, cross device heuristics ([#161767](https://github.com/pytorch/pytorch/pull/161767))
- Empty heuristics to skip decompose k on anything not cuda ([#161795](https://github.com/pytorch/pytorch/pull/161795))
- Optimize config selecting for micro gemm when number of mxn blocks can not occupy all the threads ([#161144](https://github.com/pytorch/pytorch/pull/161144))
- Check block options after broadcasting and singleton dims have been removed ([#161602](https://github.com/pytorch/pytorch/pull/161602))
- Make pattern matcher resilient to ddes ([#161843](https://github.com/pytorch/pytorch/pull/161843))
- Add notion of extra_kwargs for mm_configs ([#161123](https://github.com/pytorch/pytorch/pull/161123))
- Move tma workspace in heuristics ([#161124](https://github.com/pytorch/pytorch/pull/161124))
- Move addmm/baddbmm template args into heuristics ([#161125](https://github.com/pytorch/pytorch/pull/161125))
- Move scaled_mm template args into heuristics ([#161126](https://github.com/pytorch/pytorch/pull/161126))
- ExternChoice with maybe_append_choice ([#161336](https://github.com/pytorch/pytorch/pull/161336))
- Pass through layout and input_nodes ([#161338](https://github.com/pytorch/pytorch/pull/161338))
- Get Inductor kernel params ([#161953](https://github.com/pytorch/pytorch/pull/161953))
- Fix split_aot_inductor_output_path on Windows. ([#162058](https://github.com/pytorch/pytorch/pull/162058))
- Fix AMD User Defined Kernel Autotune ([#161521](https://github.com/pytorch/pytorch/pull/161521))
- Apply Triton tensor descriptor for flex-decoding for performance ([#161643](https://github.com/pytorch/pytorch/pull/161643))
- Forward fix for user defined triton kernel grid calc ([#162162](https://github.com/pytorch/pytorch/pull/162162))
- Register triton template heuristic for addmm tma. ([#162132](https://github.com/pytorch/pytorch/pull/162132))
- Allow for using a dedicated binary for the torch subproc pool. ([#162093](https://github.com/pytorch/pytorch/pull/162093))
- Add Kernel name to all coor-desc tuning ([#161409](https://github.com/pytorch/pytorch/pull/161409))
- Enable TMA path on Intel GPU ([#162138](https://github.com/pytorch/pytorch/pull/162138))
- Mild refactor on contigous mm ([#162075](https://github.com/pytorch/pytorch/pull/162075))
- Move scaled_mm input nodes logic ([#161340](https://github.com/pytorch/pytorch/pull/161340))
- Add template/externchoice uid ([#161341](https://github.com/pytorch/pytorch/pull/161341))
- Treat like a template in GEMMs ([#161342](https://github.com/pytorch/pytorch/pull/161342))
- Pass template rather than template.uid ([#161343](https://github.com/pytorch/pytorch/pull/161343))
- Move max-autotune logic inside V.choices.get_mm_configs ([#161344](https://github.com/pytorch/pytorch/pull/161344))
- Return choicecallers directly ([#161345](https://github.com/pytorch/pytorch/pull/161345))
- V.choice.get_mm_configs takes a stack of templates ([#161346](https://github.com/pytorch/pytorch/pull/161346))
- Estimate peak memory in codegen only when buffer reuse ([#162300](https://github.com/pytorch/pytorch/pull/162300))
- Fix TemplateBuffer.extract_read_writes ([#162221](https://github.com/pytorch/pytorch/pull/162221))
- Rename deps during refreshing ([#162303](https://github.com/pytorch/pytorch/pull/162303))
- More JITCallable._hash_lock support ([#162244](https://github.com/pytorch/pytorch/pull/162244))
- Add helper sizevars function, is_size_one, for size==1 checks ([#162189](https://github.com/pytorch/pytorch/pull/162189))
- normalize path of the code. ([#159255](https://github.com/pytorch/pytorch/pull/159255))
- Integrate kernacle into inductor ([#160121](https://github.com/pytorch/pytorch/pull/160121))
- Moving torch.compile worker process logs to a dedicated rank based log directory ([#160352](https://github.com/pytorch/pytorch/pull/160352))
- Set PYTHONHOME for inductor subprocesses using torch ([#160008](https://github.com/pytorch/pytorch/pull/160008))
- Add float16 support for CppMicroGemmAMX ([#147368](https://github.com/pytorch/pytorch/pull/147368))
- Update Intel Triton for PyTorch 2.9. ([#161050](https://github.com/pytorch/pytorch/pull/161050))
- Update triton pin to triton 3.5 ([#162278](https://github.com/pytorch/pytorch/pull/162278))
- Add zero size consts asm handler ([#159225](https://github.com/pytorch/pytorch/pull/159225))
- Skip some AOTI UTs on Windows. ([#160287](https://github.com/pytorch/pytorch/pull/160287))
- Fix test output path AOTI ([#162085](https://github.com/pytorch/pytorch/pull/162085))
- Skip stream k if shape is dynamic ([#159442](https://github.com/pytorch/pytorch/pull/159442))
- Copy cutlass_mock_imports directory ([#159724](https://github.com/pytorch/pytorch/pull/159724))
- Reduce severity of log message for no cutlass config found ([#160148](https://github.com/pytorch/pytorch/pull/160148))
- Allow bmm use cases when batch stride is 0 ([#160356](https://github.com/pytorch/pytorch/pull/160356))
- Update the guard semantics for divisibility ([#159884](https://github.com/pytorch/pytorch/pull/159884))
- Flex Attention heuristics: a Blackwell config ([#160192](https://github.com/pytorch/pytorch/pull/160192))
- forward fix on fp32_precision ([#161465](https://github.com/pytorch/pytorch/pull/161465))
- Enable XPU path for FlexAttention ([#143553](https://github.com/pytorch/pytorch/pull/143553))
### Untopiced
### security


# Release Notes worksheet inductor

The main goal of this process is to rephrase all the commit messages below to make them **clear and easy to read** by the end user. You should follow the following instructions to do so:

* **Please clean up and format commit titles to be readable by the general PyTorch user.** Make sure you're [following the guidance here](https://docs.google.com/document/d/14OmgGBr1w6gl1VO47GGGdwrIaUNr92DFhQbY_NEk8mQ/edit)! Your resulting notes must be consistent and easy to read.
* Please sort commits into the following categories (you should not rename the categories!), I tried to pre-sort these to ease your work, feel free to move commits around if the current categorization is not good.
* Anything that is not public facing needs to be removed.
* If anything is miscategorized/belongs to another domain, move it to `miscategorized.md`.
* Please scan through `miscategorized.md` and handle any commits that belong within your domain according to these instructions.
* We place a lot of emphasis on the “BC-breaking” and “deprecation” sections. Those should be where the most effort goes in. The “improvements” and “bug fixes” for Python API should be nice as well.
* Once you are finished, move this very file from `todo/` to `done/` and submit a pull request.

The categories below are as follows:

* BC breaking: All commits that are BC-breaking. These are the most important commits. If any pre-sorted commit is actually BC-breaking, do move it to this section. Each commit should contain a paragraph explaining the rational behind the change as well as an example for how to update user code [BC-Guidelines](https://docs.google.com/document/d/14OmgGBr1w6gl1VO47GGGdwrIaUNr92DFhQbY_NEk8mQ/edit#heading=h.a9htwgvvec1m).
* Deprecations: All commits introducing deprecation. Each commit should include a small example explaining what should be done to update user code.
* new_features: All commits introducing a new feature (new functions, new submodule, new supported platform etc)
* improvements: All commits providing improvements to existing feature should be here (new backend for a function, new argument, better numerical stability)
* bug fixes: All commits that fix bugs and behaviors that do not match the documentation
* performance: All commits that are added mainly for performance (we separate this from improvements above to make it easier for users to look for it)
* documentation: All commits that add/update documentation
* Developers: All commits that are not end-user facing but still impact people that compile from source, develop into pytorch, extend pytorch, etc
* not user facing: All commits that are not public end-user facing and hence should be dropped from the release notes

## inductor
### bc breaking
### deprecation
### new features
- Add contiguous subgraph transformation threshold ([#162192](https://github.com/pytorch/pytorch/pull/162192))
### improvements
- Inductor logging + analysis of torch.profile ([#149697](https://github.com/pytorch/pytorch/pull/149697))
- Inductor logging + analysis of torch.profile ([#149697](https://github.com/pytorch/pytorch/pull/149697))
- Inductor logging + analysis of torch.profile ([#149697](https://github.com/pytorch/pytorch/pull/149697))
- Add profiler analysis flag to combine multiple profiles into one ([#161145](https://github.com/pytorch/pytorch/pull/161145))
### bug fixes
- Fix meta for constant_pad_nd ([#159878](https://github.com/pytorch/pytorch/pull/159878))
### performance
### docs
- Add better typing to avaialbe kernel options for flex attention ([#158383](https://github.com/pytorch/pytorch/pull/158383))
### devs
### Untopiced
- avoid to declare an unknown bound array without any element ([#156543](https://github.com/pytorch/pytorch/pull/156543))
- unify dynamic shapes API namings 3 (guard_int, guard_int_seq) ([#155973](https://github.com/pytorch/pytorch/pull/155973))
- add torch.concat to normalization pass ([#156574](https://github.com/pytorch/pytorch/pull/156574))
- [Triton] [Inductor[ Add tt.descriptor_store to get_tma_stores ([#157212](https://github.com/pytorch/pytorch/pull/157212))
- Fix incorrect stride handling in adaptive_avg_pool3d ([#157326](https://github.com/pytorch/pytorch/pull/157326))
- [inductor] Fix fractional_max_pool2d 3D input causing assertion error ([#156912](https://github.com/pytorch/pytorch/pull/156912))
- [Inductor] Support precomputed size args in the FX backend.  ([#157758](https://github.com/pytorch/pytorch/pull/157758))
- [Optimus] Fix normalization pass in the aten IR ([#157857](https://github.com/pytorch/pytorch/pull/157857))
- [inductor] fix tensor.to(uint8) error when tensor src type is float  ([#157267](https://github.com/pytorch/pytorch/pull/157267))
- [inductor] re-enable TMA templates w/ AOTI ([#157819](https://github.com/pytorch/pytorch/pull/157819))
- [AOTI] codegen for static linkage ([#157129](https://github.com/pytorch/pytorch/pull/157129))
- [APS] Expose max_autotune lookup table config to frontend ([#158070](https://github.com/pytorch/pytorch/pull/158070))
- [inductor][triton] Add experimental use_tensor_descriptor config option ([#157906](https://github.com/pytorch/pytorch/pull/157906))
- [Optimus] add einsum_to_pointwise_pass pattern ([#155666](https://github.com/pytorch/pytorch/pull/155666))
- forward fix lint ([#158448](https://github.com/pytorch/pytorch/pull/158448))
- Add stack trace to Inductor IR nodes  if `inductor.config.trace.provenance_tracing=True` ([#158576](https://github.com/pytorch/pytorch/pull/158576))
- [Inductor] MSVC use pointer when generating temporary array pointer ([#158913](https://github.com/pytorch/pytorch/pull/158913))
- [Inductor] Fix a user-defined Triton kernel bool param codegen issue ([#158845](https://github.com/pytorch/pytorch/pull/158845))
- [inductor][cpu] Stop lowering div to reciprocal multiplication to preserve precision when the divisor is a scalar and device is on cpu ([#158231](https://github.com/pytorch/pytorch/pull/158231))
- Add inputs and outputs in Triton Kernel FX Graph segment ([#158174](https://github.com/pytorch/pytorch/pull/158174))
- [Optimus] Support decompose mm with dynamic shapes ([#158821](https://github.com/pytorch/pytorch/pull/158821))
- Enable dynamic shapes for foreach operations by default ([#158985](https://github.com/pytorch/pytorch/pull/158985))
- [ROCm][CK][Inductor] enable gfx950 for max autotune with CK ([#159195](https://github.com/pytorch/pytorch/pull/159195))
- [cutlass] rename EVT args within kernels for code caching ([#159243](https://github.com/pytorch/pytorch/pull/159243))
- All custom operators go through Inductor's graph.call_function ([#159174](https://github.com/pytorch/pytorch/pull/159174))
- [AOTInductor] Add test for enabling CUDACachingAllocator for AOTInductor's Weight ([#159279](https://github.com/pytorch/pytorch/pull/159279))
- [inductor] respect layout tags for ops with registered lowerings ([#159134](https://github.com/pytorch/pytorch/pull/159134))
- [Cutlass] Fix wrapper code generation breakage ([#159760](https://github.com/pytorch/pytorch/pull/159760))
- [AOTI] don't allow int32 indices if {non-inf, > int32_max} upper bound is provided ([#159433](https://github.com/pytorch/pytorch/pull/159433))
- [Cutlass] Allow offsets to be passed as arguments to kernel ([#159761](https://github.com/pytorch/pytorch/pull/159761))
- [inductor] [cpu] fix the dype hardcoded to int64 in store_reduction ([#157904](https://github.com/pytorch/pytorch/pull/157904))
- [inductor][triton] support profile_scratch launcher arg ([#159772](https://github.com/pytorch/pytorch/pull/159772))
- [Inductor] [Triton] Enable Configuration warmup/rep iterations when benchmarking in inductor ([#159982](https://github.com/pytorch/pytorch/pull/159982))
- [FlexAttention] Swap from and to & for new triton ([#160227](https://github.com/pytorch/pytorch/pull/160227))
- [inductor] remove no_x_dim ([#159810](https://github.com/pytorch/pytorch/pull/159810))
- fix cpp builder to avoid missing-source compile error ([#160354](https://github.com/pytorch/pytorch/pull/160354))
- [Inductor][Triton] Pass GPUTarget param to updated make_ir function ([#160422](https://github.com/pytorch/pytorch/pull/160422))
- [inductor][triton] Update triton_builtin handling after triton # 7239 ([#160658](https://github.com/pytorch/pytorch/pull/160658))
- [dynamic shapes] handle Max(*,1) for inductor layout contiguity ([#160578](https://github.com/pytorch/pytorch/pull/160578))
- [AOTInductor] ABI-Compatibility for RecordFunction. ([#159842](https://github.com/pytorch/pytorch/pull/159842))
- [Inductor] modify convert_to_reinterpret_view ([#158914](https://github.com/pytorch/pytorch/pull/158914))
- [inductor] pack linear for FP32 dynamic mode ([#157542](https://github.com/pytorch/pytorch/pull/157542))
- [export] Fix custom ops in subgraphs ([#160004](https://github.com/pytorch/pytorch/pull/160004))
- [Inductor] add cuda compile cmd to autotuning logging ([#160906](https://github.com/pytorch/pytorch/pull/160906))
- Add kernel information JSON generation for AOTI packages ([#160540](https://github.com/pytorch/pytorch/pull/160540))
- [Optimus][decompose_mm] Fix BooleanAtom corner case ([#160987](https://github.com/pytorch/pytorch/pull/160987))
- FlexDecode not guarding on GQA groups correctly ([#160904](https://github.com/pytorch/pytorch/pull/160904))
- [AOTI] Add a new config cpp.use_constexpr_for_int_array ([#160927](https://github.com/pytorch/pytorch/pull/160927))
- [Cutlass-EVT] Fix buffer size issues ([#161335](https://github.com/pytorch/pytorch/pull/161335))
- Add debug handle to inductor provenance tracking ([#161110](https://github.com/pytorch/pytorch/pull/161110))
- [inductor][triton] support JITCallable._hash_lock ([#161768](https://github.com/pytorch/pytorch/pull/161768))
- [FlexAttn] Fix Paged Attention Accuracy via Upper Mask Mod and Prevent Invalid Memory Access  ([#160861](https://github.com/pytorch/pytorch/pull/160861))
- [Inductor] update exp codegen for better precision ([#161829](https://github.com/pytorch/pytorch/pull/161829))
- [inductor] Follow integer overflow rules in TypedExpr ([#161922](https://github.com/pytorch/pytorch/pull/161922))
- [Quant][Inductor][CPU] add qlinear int8-mixed-bf16 patterns ([#161486](https://github.com/pytorch/pytorch/pull/161486))
- [Quant][Inductor][CPU] add qconv int8-mixed-bf16 patterns ([#161487](https://github.com/pytorch/pytorch/pull/161487))
- Add torch.compile support for triton.constexpr_function ([#162106](https://github.com/pytorch/pytorch/pull/162106))
- Fix memory leak in AOTI when calling `aoti_torch_as_strided` ([#162118](https://github.com/pytorch/pytorch/pull/162118))
- [Graph Partition] interface for custom cg wrapper ([#162207](https://github.com/pytorch/pytorch/pull/162207))
- [inductor][triton] support static cuda launcher after triton # 7866 ([#162309](https://github.com/pytorch/pytorch/pull/162309))
- [Inductor] Fix cross-device scalar lowering - cpu scalar with cuda tensor fails in torch.compile ([#161447](https://github.com/pytorch/pytorch/pull/161447))
### not user facing
- [inductor] select_algorithm: add preprocessing fns ([#156464](https://github.com/pytorch/pytorch/pull/156464))
- [cutlass backend] delete pip cutlass path since nvidia stops supporting nvidia-cutlass ([#156651](https://github.com/pytorch/pytorch/pull/156651))
- Unify dynamic shapes APIs naming 2 (expect_true and check) attempt2 ([#156518](https://github.com/pytorch/pytorch/pull/156518))
- [Inductor] Restrict block analysis to only match integer dims and strides ([#149615](https://github.com/pytorch/pytorch/pull/149615))
- [ez] fix typo in select_algorithm.py ([#156625](https://github.com/pytorch/pytorch/pull/156625))
- [ez] fix typo in comment ([#156402](https://github.com/pytorch/pytorch/pull/156402))
- Add a crash handler to async compile subprocesses ([#155068](https://github.com/pytorch/pytorch/pull/155068))
- [cutlass backend] compile and link for .so files ([#155876](https://github.com/pytorch/pytorch/pull/155876))
- [cutlass backend] Move cutlass key to cutlass_library ([#156654](https://github.com/pytorch/pytorch/pull/156654))
- [precompile] When using BundledAOTAutogradCache, disable FXGraphCache ([#156611](https://github.com/pytorch/pytorch/pull/156611))
- [ez] add docblock and comments to simd.split_and_set_ranges ([#156717](https://github.com/pytorch/pytorch/pull/156717))
- Bump STATIC_CUDA_LAUNCHER_VERSION to 2 ([#156726](https://github.com/pytorch/pytorch/pull/156726))
- [ez] Add docblock for SchedulerNode.codegen ([#156718](https://github.com/pytorch/pytorch/pull/156718))
- [cutlass] rename cutlass python lib to python-cutlass ([#156655](https://github.com/pytorch/pytorch/pull/156655))
- [BE] comments + try to get rid of secondary `make_autotune_fn` ([#156358](https://github.com/pytorch/pytorch/pull/156358))
- [Inductor][CLN] Remove unused default configs in `flex_attention.py` ([#156700](https://github.com/pytorch/pytorch/pull/156700))
- [BE] Remove CXX11_ABI references from cpp_builder.py ([#156896](https://github.com/pytorch/pytorch/pull/156896))
- [BE] Deprecate `search_autotune_cache` ([#155302](https://github.com/pytorch/pytorch/pull/155302))
- [PT2] deprecate `force_same_precision`, guarded by JK ([#156789](https://github.com/pytorch/pytorch/pull/156789))
- [Inductor][CPP] Fix perf regression of functorch_maml_omniglot ([#156526](https://github.com/pytorch/pytorch/pull/156526))
- [test][inductor] fix test_conv_cat failure ([#155852](https://github.com/pytorch/pytorch/pull/155852))
- Rename mm_scaled_grouped.py to mm_grouped.py ([#156849](https://github.com/pytorch/pytorch/pull/156849))
- [async compile] make it more obvious that we support backwards ([#157204](https://github.com/pytorch/pytorch/pull/157204))
- [inductor] Increase tolerance for test_comprehensive_nn_functional_linear_cuda_float16 ([#156962](https://github.com/pytorch/pytorch/pull/156962))
- [AOTI] Print out error msg when nvcc compiler fails ([#157203](https://github.com/pytorch/pytorch/pull/157203))
- [Inductor] add pedantic to limit inductor code follow standard. ([#156914](https://github.com/pytorch/pytorch/pull/156914))
- [inductor] Update triton_key import to support latest Triton ([#157242](https://github.com/pytorch/pytorch/pull/157242))
- [FP8] Fix Benchmarking for certain Priors ([#155722](https://github.com/pytorch/pytorch/pull/155722))
- [inductor] enable bf32 test for mkldnn conv ([#127293](https://github.com/pytorch/pytorch/pull/127293))
- [Inductor] Disable decompose_k for AMD ([#157283](https://github.com/pytorch/pytorch/pull/157283))
- [BE][DCE] eliminate remnants of global gemm cache ([#157327](https://github.com/pytorch/pytorch/pull/157327))
- [inductor] more size_hint_or_throw usage ([#157394](https://github.com/pytorch/pytorch/pull/157394))
- [cutlass backend] Use alignment of D for EVT / Float8 ([#157402](https://github.com/pytorch/pytorch/pull/157402))
- [cutlass backend] Add dynamo timed ([#157410](https://github.com/pytorch/pytorch/pull/157410))
- Move logging into inner method for reorder pass ([#156879](https://github.com/pytorch/pytorch/pull/156879))
- Fixed triton kernel in ET due to Triton version change. ([#157484](https://github.com/pytorch/pytorch/pull/157484))
- [cutlass backend] modify presets ahead of cutlass 4 upgrade ([#157522](https://github.com/pytorch/pytorch/pull/157522))
- [async-compile] add progressive compile mode ([#157305](https://github.com/pytorch/pytorch/pull/157305))
- [pc] migrate progression futures from list to deque ([#157614](https://github.com/pytorch/pytorch/pull/157614))
- [pc] introduce ProgressiveCompilationState and clear callback ([#157619](https://github.com/pytorch/pytorch/pull/157619))
- [inductor] enable bf32 for mkldnn linear pointwise/binary in inductor ([#127294](https://github.com/pytorch/pytorch/pull/127294))
- [fbcode] switch to cutlass-4 ([#157579](https://github.com/pytorch/pytorch/pull/157579))
- [logging] [redo] dynamo_timed for CachingAutotuner.coordinate_descent_tuning ([#156840](https://github.com/pytorch/pytorch/pull/156840))
- Split batch-num-heads grid dim between y and z ([#157745](https://github.com/pytorch/pytorch/pull/157745))
- Check FakeScriptObject in _resolve_name_collision ([#157736](https://github.com/pytorch/pytorch/pull/157736))
- [inductor] Quiesce Triton compile worker pool after each dynamo compile ([#156187](https://github.com/pytorch/pytorch/pull/156187))
- [Windows][Inductor] normalize_path_separator compiler path ([#157835](https://github.com/pytorch/pytorch/pull/157835))
- Adding aoti_standalone config ([#157731](https://github.com/pytorch/pytorch/pull/157731))
- [AOTI] add flag AOT_INDUCTOR_ENABLE_LTO ([#157773](https://github.com/pytorch/pytorch/pull/157773))
- [inductor] support unbacked symint in sdpfa ([#157739](https://github.com/pytorch/pytorch/pull/157739))
- [Inductor] Introduce Lookup Table for Overriding Triton Kernel autotune configs post fusion ([#157924](https://github.com/pytorch/pytorch/pull/157924))
- Fixed the function to get the origin nodes of fused triton kernel. ([#157578](https://github.com/pytorch/pytorch/pull/157578))
- [standalone_compile] Fix single Tensor outputs from split_module ([#157803](https://github.com/pytorch/pytorch/pull/157803))
- [logging] dynamo_timed the synchronize in CachingAutotuner make_launchers ([#157747](https://github.com/pytorch/pytorch/pull/157747))
- [cutlass backend] Make config request key depend on serialization.py and cutlass_utils.py ([#157839](https://github.com/pytorch/pytorch/pull/157839))
- [cutlass backend] Change serialization protocol to use more json and cache ([#157840](https://github.com/pytorch/pytorch/pull/157840))
- Support caching if joint_custom_pre_pass/joint_custom_post_pass implement the proper interface ([#157990](https://github.com/pytorch/pytorch/pull/157990))
- Fix is_unaligned usage of statically_known_true ([#157845](https://github.com/pytorch/pytorch/pull/157845))
- Return false in statically_known_multiple_of if numerator has more than 20 unique symbols ([#157855](https://github.com/pytorch/pytorch/pull/157855))
- [ROCm][Inductor][CK] update API for gemm-multiD change ([#156122](https://github.com/pytorch/pytorch/pull/156122))
- Add size_hints to cache key ([#158026](https://github.com/pytorch/pytorch/pull/158026))
- [Bugfix][Inductor] Fix dependency list merged incorrectly for a custom op with multiple mutated inputs and None return type. ([#157133](https://github.com/pytorch/pytorch/pull/157133))
- [aot] add format_consts_to_cpp function for further development. ([#157608](https://github.com/pytorch/pytorch/pull/157608))
- [cutlass backend] Global filter ops before situation based filter ops ([#157866](https://github.com/pytorch/pytorch/pull/157866))
- Make Q Indices optional ([#157997](https://github.com/pytorch/pytorch/pull/157997))
- [aot inductor] fix clang-asan for consts_cpp. ([#158175](https://github.com/pytorch/pytorch/pull/158175))
- Fix XPU CI UT test_circular_dependencies ([#158189](https://github.com/pytorch/pytorch/pull/158189))
- redo of [Inductor][Cutlass] verify cutlass has cache_file attribute before moving...resolves cutlass cute exception ([#158206](https://github.com/pytorch/pytorch/pull/158206))
- [cutlass backend] cache a few things for codegen and properties ([#158158](https://github.com/pytorch/pytorch/pull/158158))
- Fix torchrec multiprocess tests ([#158159](https://github.com/pytorch/pytorch/pull/158159))
- [Inductor] Add CPU_MAX_FIRST_DIMENSION_DECOMPOSITION and CPU_MAX_OTHER_DIMENSION_DECOMPOSITION for decompose_mm_pass ([#158183](https://github.com/pytorch/pytorch/pull/158183))
- [AOTI][CPP] add flag TORCHINDUCTOR_CPP_FORCE_INLINE_KERNEL ([#157949](https://github.com/pytorch/pytorch/pull/157949))
- Fix grouped MM output strides when compiled but not max-autotuned ([#158143](https://github.com/pytorch/pytorch/pull/158143))
- Fix types in graphs.py ([#158192](https://github.com/pytorch/pytorch/pull/158192))
- add sfdp pattern ([#155792](https://github.com/pytorch/pytorch/pull/155792))
- [inductor] fix windows path for fresh cache. ([#158324](https://github.com/pytorch/pytorch/pull/158324))
- [AOTI] add -lstdc++ into aoti link cmd for Meta internal ([#158325](https://github.com/pytorch/pytorch/pull/158325))
- [Inductor][Triton] Update TMA Compatibility Requirements ([#157881](https://github.com/pytorch/pytorch/pull/157881))
- [aot][XPU] switch xpu to use consts cpp build. ([#158425](https://github.com/pytorch/pytorch/pull/158425))
- inductor: Fix crash in split_cat when tensors is a Node ([#157155](https://github.com/pytorch/pytorch/pull/157155))
- [AOTI] Use format_consts_to_cpp on Windows. ([#158543](https://github.com/pytorch/pytorch/pull/158543))
- [AOTI] align signature to model_base.h ([#158554](https://github.com/pytorch/pytorch/pull/158554))
- [AOTI] skip ld and objcopy on Windows. ([#158545](https://github.com/pytorch/pytorch/pull/158545))
- Revert "[PT2][fusion] ban fusions with large accumulated reads (#157563) ([#158550](https://github.com/pytorch/pytorch/pull/158550))
- [B200] Fix flex-attention heuristic for `test_tma_with_customer_kernel_options_cuda` ([#158494](https://github.com/pytorch/pytorch/pull/158494))
- [inductor] Explicitly link c10 in inductor. ([#158622](https://github.com/pytorch/pytorch/pull/158622))
- [inductor] Make times and repeat parameters command line args ([#158590](https://github.com/pytorch/pytorch/pull/158590))
- pt2_remote_cache: Log sample for failures, and log the explicit reason we're faling. ([#156874](https://github.com/pytorch/pytorch/pull/156874))
- [AOTI] Use libstdc++ only for fbcode cpu case ([#158659](https://github.com/pytorch/pytorch/pull/158659))
- enable_caching_generated_triton_templates=True by default ([#158592](https://github.com/pytorch/pytorch/pull/158592))
- [inductor][templates] Finalize all registered hooks ([#157270](https://github.com/pytorch/pytorch/pull/157270))
- [Optimus][Unit test] clean up the unit test ([#158696](https://github.com/pytorch/pytorch/pull/158696))
- [cutlass backend] cache maybe_append_choices ([#156781](https://github.com/pytorch/pytorch/pull/156781))
- ban fusion of large amount of reads ([#158667](https://github.com/pytorch/pytorch/pull/158667))
- [cutass backend] memorize parts of cache key to reduce general overhead ([#158311](https://github.com/pytorch/pytorch/pull/158311))
- [reland] Transfer "stack_trace" in post_grad passes ([#158752](https://github.com/pytorch/pytorch/pull/158752))
- [bucketing] Support case of several pgs in graph ([#158632](https://github.com/pytorch/pytorch/pull/158632))
- [inductor] pass_fds not supported on Windows, skip them on Windows. ([#158830](https://github.com/pytorch/pytorch/pull/158830))
- [inductor] support linear & layer_norm unbacked ([#155267](https://github.com/pytorch/pytorch/pull/155267))
- [pt2 event logging] send autotuning data for strides and hinted shapes ([#158852](https://github.com/pytorch/pytorch/pull/158852))
- [inductor] Allow backends to register their own custom config object ([#158254](https://github.com/pytorch/pytorch/pull/158254))
- [AOTI] enable aot inductor on Windows ([#158915](https://github.com/pytorch/pytorch/pull/158915))
- [inductor] Fix collectives_reordering overwrite real_dep with fake_dep with the same name ([#158960](https://github.com/pytorch/pytorch/pull/158960))
- [inductor] add missing ignore_errors parameter for Windows. ([#159025](https://github.com/pytorch/pytorch/pull/159025))
- Add more type hints for _inductor/ir.py ([#159049](https://github.com/pytorch/pytorch/pull/159049))
- [inductor] fix test_save_graph_repro on Windows. ([#159148](https://github.com/pytorch/pytorch/pull/159148))
- Fix full_like decomposition to preserve strides ([#158898](https://github.com/pytorch/pytorch/pull/158898))
- [Inductor] disable windows failed UTs temporary. ([#159163](https://github.com/pytorch/pytorch/pull/159163))
- [Inductor][TMA] Split config-gated and pure compatibility logic for TMA template eligibility checks ([#159123](https://github.com/pytorch/pytorch/pull/159123))
- [Inductor] [Triton] Enabling TMA for flex-attention for supported device types ([#157822](https://github.com/pytorch/pytorch/pull/157822))
- [inductor] enable compiled autograd on CPU windows - v2 ([#159185](https://github.com/pytorch/pytorch/pull/159185))
- [inductor] Update `to(tl.int8).to(tl.uint8)` workaround from #94717 to handle entire range of `torch.uint8` ([#158567](https://github.com/pytorch/pytorch/pull/158567))
- [inductor] disable failed UTs of test_misc.py ([#159210](https://github.com/pytorch/pytorch/pull/159210))
- Name Inductor's Subproc pool threads. ([#158815](https://github.com/pytorch/pytorch/pull/158815))
- [TF32][Flex Attention] Turn off TF32 for reference computation in `test_flex_decoding` ([#158979](https://github.com/pytorch/pytorch/pull/158979))
- [inductor] normalize path of the code. ([#159255](https://github.com/pytorch/pytorch/pull/159255))
- [Re-land][Inductor] Support native Inductor as backend for MTIA ([#159211](https://github.com/pytorch/pytorch/pull/159211))
- Fix inductor cuda sort nan behavior ([#159308](https://github.com/pytorch/pytorch/pull/159308))
- [BE] Eliminate workspace info in templates with new API ([#159055](https://github.com/pytorch/pytorch/pull/159055))
- Add user annotation for FX graph cache key ([#159318](https://github.com/pytorch/pytorch/pull/159318))
- [Graph Partition] add graph partition doc ([#159450](https://github.com/pytorch/pytorch/pull/159450))
- [Code Motion]Restructure flex attention kernel into flex subdirectory ([#159437](https://github.com/pytorch/pytorch/pull/159437))
- Don't use torch.backends.cuda.matmul.allow_tf32 in inductor cache key ([#159480](https://github.com/pytorch/pytorch/pull/159480))
- Check addmm dtypes ([#159509](https://github.com/pytorch/pytorch/pull/159509))
- [Triton] [Inductor] Fix an incorrect descriptor ([#159407](https://github.com/pytorch/pytorch/pull/159407))
- torch.compile: Record a pt2_compile_event for combo kernels ([#159306](https://github.com/pytorch/pytorch/pull/159306))
- [Graph Partition] add log for graph partition reasons and #partitions ([#159425](https://github.com/pytorch/pytorch/pull/159425))
- [inductor] fix open temp file failed on Windows. ([#159342](https://github.com/pytorch/pytorch/pull/159342))
- [inductor] Fix set_linter's handling of f-strings for Python 3.12 and up (fix #159056) ([#159252](https://github.com/pytorch/pytorch/pull/159252))
- [inductor] add lowering for repeat_interleave.Tensor with output size specified (#147160) ([#158462](https://github.com/pytorch/pytorch/pull/158462))
- Fix grouped MM load along K when TMA loads are not used ([#159485](https://github.com/pytorch/pytorch/pull/159485))
- [AOTI] add zero size consts asm handler ([#159225](https://github.com/pytorch/pytorch/pull/159225))
- Remove dynamo_timed from the CachingAutotuner.coordinate_descent_tuning() hot path. ([#159588](https://github.com/pytorch/pytorch/pull/159588))
- [cutlass backend] skip stream k if shape is dynamic ([#159442](https://github.com/pytorch/pytorch/pull/159442))
- Log autotune choices and benchmark result to scuba/chrome trace ([#159496](https://github.com/pytorch/pytorch/pull/159496))
- [bucketing] Use max of input/output size for bucketing ([#159717](https://github.com/pytorch/pytorch/pull/159717))
- [bucketing] Reduce CPU overhead for reduce_scatter_merge_fn_to_trace ([#159723](https://github.com/pytorch/pytorch/pull/159723))
- Fix warnings in triton_helpers.py ([#159719](https://github.com/pytorch/pytorch/pull/159719))
- S390X: fix detection of magic number placeholder in inductor ([#157784](https://github.com/pytorch/pytorch/pull/157784))
- [typing] Constrain OrderedSet generic to be Hashable ([#159684](https://github.com/pytorch/pytorch/pull/159684))
- [inductor] use writable temp file on windows ([#159738](https://github.com/pytorch/pytorch/pull/159738))
- Revert "[inductor] add lowering for repeat_interleave.Tensor with output size specified (#147160) (#158462)" ([#159798](https://github.com/pytorch/pytorch/pull/159798))
- DeviceCopy should have the same layout as input ([#159615](https://github.com/pytorch/pytorch/pull/159615))
- Add cascade sum support for Inductor CPP backend ([#156296](https://github.com/pytorch/pytorch/pull/156296))
- [Inductor] Revert minimal changes to avoid internal test failures ([#159809](https://github.com/pytorch/pytorch/pull/159809))
- [inductor] Add TLParse artifact for logging runtime of collective and compute ops ([#159730](https://github.com/pytorch/pytorch/pull/159730))
- Extract some HOP utils to be importable ([#159705](https://github.com/pytorch/pytorch/pull/159705))
- Wire in pt2_triton_builds ([#159897](https://github.com/pytorch/pytorch/pull/159897))
- [inductor] add _get_inductor_debug_symbol_cflags for debug symbol control. ([#159938](https://github.com/pytorch/pytorch/pull/159938))
- [inductor][ez] fixup scaled_mm ([#159948](https://github.com/pytorch/pytorch/pull/159948))
- Remove unnecessary "# noqa: set_linter" comments ([#159467](https://github.com/pytorch/pytorch/pull/159467))
- [FlexAttention] Update the guard semantics for divisibility ([#159884](https://github.com/pytorch/pytorch/pull/159884))
- [inductor] fix test_dynamo_timed on Windows. ([#159981](https://github.com/pytorch/pytorch/pull/159981))
- [inductor] unification for inductor debug. ([#159998](https://github.com/pytorch/pytorch/pull/159998))
- [inductor] disable flex decoding on Windows. ([#160072](https://github.com/pytorch/pytorch/pull/160072))
- Log max_autotune exceptions (#159687) ([#159688](https://github.com/pytorch/pytorch/pull/159688))
- integrate kernacle into inductor ([#160121](https://github.com/pytorch/pytorch/pull/160121))
- Do not treat ReinterpretView as a realized node ([#159920](https://github.com/pytorch/pytorch/pull/159920))
- [Inductor][CUTLASS] Copy cutlass_mock_imports directory ([#159724](https://github.com/pytorch/pytorch/pull/159724))
- [inductor] fix CompiledArtifact.load path on Windows. ([#160268](https://github.com/pytorch/pytorch/pull/160268))
- [inductor] slow test some Windows UTs. ([#160267](https://github.com/pytorch/pytorch/pull/160267))
- [Inductor] Add back the revert part ([#160054](https://github.com/pytorch/pytorch/pull/160054))
- [inductor] fix some windows inductor UTs ([#160292](https://github.com/pytorch/pytorch/pull/160292))
- [inductor] normalize_path_separator for test_different_file_paths_local_pgo ([#160286](https://github.com/pytorch/pytorch/pull/160286))
- [inductor] Skip some AOTI UTs on Windows. ([#160287](https://github.com/pytorch/pytorch/pull/160287))
- Fix collective schedule logging and runtime tests ([#160260](https://github.com/pytorch/pytorch/pull/160260))
- [inductor] fix test_different_file_paths_local_pgo on Windows. ([#160382](https://github.com/pytorch/pytorch/pull/160382))
- [BE][cutlass backend] Reduce severity of log message for no cutlass config found ([#160148](https://github.com/pytorch/pytorch/pull/160148))
- [redone][pytorch] Moving torch.compile worker process logs to a dedicated rank based log directory ([#160352](https://github.com/pytorch/pytorch/pull/160352))
- [inductor] fix triton bucketize mask propagation ([#159961](https://github.com/pytorch/pytorch/pull/159961))
- [BE] Save attributes for CppCompileError for pickleing ([#160294](https://github.com/pytorch/pytorch/pull/160294))
- Fix get_free_symbol_uses for several nodes ([#160314](https://github.com/pytorch/pytorch/pull/160314))
- Do not rpath CUDA stubs folder in JIT generated code ([#160179](https://github.com/pytorch/pytorch/pull/160179))
- [cutlass backend] Allow bmm use cases when batch stride is 0 ([#160356](https://github.com/pytorch/pytorch/pull/160356))
- Change IR node's stack trace to be computed lazily ([#160487](https://github.com/pytorch/pytorch/pull/160487))
- [MTIA-T][CFF] Pass backend parameter into GPU vertical pass file and pattern matcher ([#160404](https://github.com/pytorch/pytorch/pull/160404))
- [inductor] add lowering for repeat_interleave.Tensor with output size specified (#147160) ([#158462](https://github.com/pytorch/pytorch/pull/158462))
- [cutlass] fix dictionary iteration error ([#160552](https://github.com/pytorch/pytorch/pull/160552))
- Flex Attention heuristics: a Blackwell config ([#160192](https://github.com/pytorch/pytorch/pull/160192))
- [Lowering] Add assertion msg to sym_size and sym_stride ([#160591](https://github.com/pytorch/pytorch/pull/160591))
- Set PYTHONHOME for inductor subprocesses using torch ([#160008](https://github.com/pytorch/pytorch/pull/160008))
- Typo correction in variable name uninitalized_val in resize() function ([#160636](https://github.com/pytorch/pytorch/pull/160636))
- [Inductor] Allow indexing a flexible layout for extract_input_node_reduction_ranges ([#160645](https://github.com/pytorch/pytorch/pull/160645))
- [Inductor] [Triton] Apply feedback to Enable padded stride support ([#160614](https://github.com/pytorch/pytorch/pull/160614))
- raise exception in case of errors in memory reordering ([#160455](https://github.com/pytorch/pytorch/pull/160455))
- [inductor] Fix propagating  torch.utils._sympy.functions.Identity in IndexPropagation ([#155504](https://github.com/pytorch/pytorch/pull/155504))
- Change IR node's stack traces to return a set of stack traces only ([#160701](https://github.com/pytorch/pytorch/pull/160701))
- [inductor][while_loop][be] improve the readability of output handling ([#160374](https://github.com/pytorch/pytorch/pull/160374))
- guard_or_false cat ops ([#160250](https://github.com/pytorch/pytorch/pull/160250))
- Add kernel stack traces tlparse dump (#160608) ([#160779](https://github.com/pytorch/pytorch/pull/160779))
- [MTIA] add correct name for CFF in tlparse ([#160599](https://github.com/pytorch/pytorch/pull/160599))
- Add cutedsl template support to compile ([#160108](https://github.com/pytorch/pytorch/pull/160108))
- [ROCm][inductor][dashboard] Add GPT2ForSequenceClassification to use_larger_multiplier_for_smaller_tensor list ([#160001](https://github.com/pytorch/pytorch/pull/160001))
- Add signpost to provenance tracking error ([#160755](https://github.com/pytorch/pytorch/pull/160755))
- [cpp][inductor] Fix crash on bmm when input is used twice. ([#160087](https://github.com/pytorch/pytorch/pull/160087))
- Fix duplicated kernel name in kernel stack trace tracking ([#160905](https://github.com/pytorch/pytorch/pull/160905))
- [while_loop][inductor] fix aliased inputs by cloning ([#160668](https://github.com/pytorch/pytorch/pull/160668))
- Make Inductor benchmarker more compatible with Triton do_bench ([#160921](https://github.com/pytorch/pytorch/pull/160921))
- [BE][inductor] tl.dot(..., allow_tf32=...) -> tl.dot(..., input_precision=...) ([#160711](https://github.com/pytorch/pytorch/pull/160711))
- [inductor] propagate shapes in CSEVariable ([#152198](https://github.com/pytorch/pytorch/pull/152198))
- preserve node meta to fix inductor generated kernel name for pattern matched graphs ([#160542](https://github.com/pytorch/pytorch/pull/160542))
- Add tlparse artifact for joint graph passes (for inference & non-freezing only) ([#160589](https://github.com/pytorch/pytorch/pull/160589))
- [Inductor][CPP] Add float16 support for CppMicroGemmAMX ([#147368](https://github.com/pytorch/pytorch/pull/147368))
- [BE] Fix old TMA API in persistent matmul template ([#161030](https://github.com/pytorch/pytorch/pull/161030))
- [inductor] Fix descriptor broadcasting for singleton dimensions ([#160310](https://github.com/pytorch/pytorch/pull/160310))
- Allow exposing more functions during initial template expansion ([#159554](https://github.com/pytorch/pytorch/pull/159554))
- [inductor][mm] fix tma issue ([#161025](https://github.com/pytorch/pytorch/pull/161025))
- [inductor] add level zero for xpu ([#161061](https://github.com/pytorch/pytorch/pull/161061))
- [inductor] Enable updated __cplusplus macro ([#161064](https://github.com/pytorch/pytorch/pull/161064))
- TritonKernel.inductor_meta_common() -> self.inductor_meta_common() ([#160895](https://github.com/pytorch/pytorch/pull/160895))
- [CPU][Inductor] improve performance of A16W4 GEMM template ([#159127](https://github.com/pytorch/pytorch/pull/159127))
- [Inductor][CPP] Fix layout for local buf in outer loop fusion ([#160857](https://github.com/pytorch/pytorch/pull/160857))
- [inductor] disable min/max macro on Windows. ([#161133](https://github.com/pytorch/pytorch/pull/161133))
- [inductor] add libraries_dirs for level_zero ([#161146](https://github.com/pytorch/pytorch/pull/161146))
- [invoke_subgraph][inductor] Thread graphsafe rng input states for hops ([#160713](https://github.com/pytorch/pytorch/pull/160713))
- forward fix of #152198 ([#161166](https://github.com/pytorch/pytorch/pull/161166))
- Avoid making node a successor/predecessor of itself ([#161205](https://github.com/pytorch/pytorch/pull/161205))
- [inductor][cpu] Fix double-offset issue in `GEMM_TEMPLATE` ([#159233](https://github.com/pytorch/pytorch/pull/159233))
- [inductor] Enable max compatible to msvc for oneAPI headers. ([#161196](https://github.com/pytorch/pytorch/pull/161196))
- [inductor] remove Windows unsupported build options. ([#161197](https://github.com/pytorch/pytorch/pull/161197))
- [inductor] Add get page_size support for Windows. ([#161273](https://github.com/pytorch/pytorch/pull/161273))
- [inductor] fix march=native pass to Windows CC. ([#161264](https://github.com/pytorch/pytorch/pull/161264))
- [FlexAttention] fixing learnable bias assertion error in inductor ([#161170](https://github.com/pytorch/pytorch/pull/161170))
- [inductor] add MSVC language pack check. ([#161298](https://github.com/pytorch/pytorch/pull/161298))
- [Inductor] Update Intel Triton for PyTorch 2.9. ([#161050](https://github.com/pytorch/pytorch/pull/161050))
- [Pattern Matcher] improve error msg ([#161423](https://github.com/pytorch/pytorch/pull/161423))
- Issue 160495 inductor complex float ([#160736](https://github.com/pytorch/pytorch/pull/160736))
- [Inductor][Triton] Fix SCALING_ROWWISE misclassification for scalar scales ([#160450](https://github.com/pytorch/pytorch/pull/160450))
- [Inductor][Tritonparse] Call `jit_post_compile_hook` within Inductor Triton Kernel compile path ([#161443](https://github.com/pytorch/pytorch/pull/161443))
- forward fix #161102 ([#161465](https://github.com/pytorch/pytorch/pull/161465))
- inductor: Log the specific triton kernel that fails ([#161452](https://github.com/pytorch/pytorch/pull/161452))
- async_compile: Fix the wait method to actually wait ([#161561](https://github.com/pytorch/pytorch/pull/161561))
- Improve Scheduler init duration ([#161491](https://github.com/pytorch/pytorch/pull/161491))
- Select Algorithm clear feedback savers ([#161654](https://github.com/pytorch/pytorch/pull/161654))
- [Inductor][WIndows] Fix Windows test case failure. ([#161497](https://github.com/pytorch/pytorch/pull/161497))
- [inductor] don't append None to choices ([#161672](https://github.com/pytorch/pytorch/pull/161672))
- [inductor][mm] restructure decompose k ([#161026](https://github.com/pytorch/pytorch/pull/161026))
- [inductor][ez] move template heuristics into dir ([#161097](https://github.com/pytorch/pytorch/pull/161097))
- [inductor][decompose-k] make part of template heuristics ([#161098](https://github.com/pytorch/pytorch/pull/161098))
- [Flex] Fix float16 default config 128 headdim ([#161647](https://github.com/pytorch/pytorch/pull/161647))
- [BE][inductor] replace "and" -> "logical_and" in bucketize_binary_search ([#160941](https://github.com/pytorch/pytorch/pull/160941))
- [inductor] Fix SubgraphInfo round trip ([#161779](https://github.com/pytorch/pytorch/pull/161779))
- [while_loop][inductor] remove offset check for while_loop ([#160669](https://github.com/pytorch/pytorch/pull/160669))
- [while_loop] avoid aliasing when body_fn never executes  ([#160670](https://github.com/pytorch/pytorch/pull/160670))
- [inductor] Lift fw_compiler and bw_compiler as toplevel functions. ([#161762](https://github.com/pytorch/pytorch/pull/161762))
- [inductor][heuristics registry] missing heuristic is not an error anymore, cross device heuristics ([#161767](https://github.com/pytorch/pytorch/pull/161767))
- [inductor][decompose k] disable on everything other than cuda ([#161795](https://github.com/pytorch/pytorch/pull/161795))
- Enable XPU path for FlexAttention ([#143553](https://github.com/pytorch/pytorch/pull/143553))
- [WIP] more aggressive persistent reduction ([#161055](https://github.com/pytorch/pytorch/pull/161055))
- [Inductor][CPP] Optimize config selecting for micro gemm when number of mxn blocks can not occupy all the threads ([#161144](https://github.com/pytorch/pytorch/pull/161144))
- [inductor] check block options after broadcasting and singleton dims have been removed ([#161602](https://github.com/pytorch/pytorch/pull/161602))
- [CPU][Inductor] Improve performance of A16W8 GEMM template ([#161148](https://github.com/pytorch/pytorch/pull/161148))
- Fix slice scatter dtype consistency ([#160851](https://github.com/pytorch/pytorch/pull/160851))
- Make pattern matcher resilient to ddes ([#161843](https://github.com/pytorch/pytorch/pull/161843))
- [inductor] add notion of extra_kwargs for mm_configs ([#161123](https://github.com/pytorch/pytorch/pull/161123))
- [inductor] move tma workspace in heuristics ([#161124](https://github.com/pytorch/pytorch/pull/161124))
- [inductor] move addmm/baddbmm template args into heuristics ([#161125](https://github.com/pytorch/pytorch/pull/161125))
- [inductor] move scaled_mm template args into heuristics ([#161126](https://github.com/pytorch/pytorch/pull/161126))
- [inductor][ez] ExternChoice with maybe_append_choice ([#161336](https://github.com/pytorch/pytorch/pull/161336))
- [inductor][choices][ez] pass through layout and input_nodes ([#161338](https://github.com/pytorch/pytorch/pull/161338))
- [Reland][Inductor] Prune configs that require more shared memory than the hardware limit.  ([#161996](https://github.com/pytorch/pytorch/pull/161996))
- [Inductor][Tritonparse] Get Inductor kernel params ([#161953](https://github.com/pytorch/pytorch/pull/161953))
- [inductor] fix split_aot_inductor_output_path on Windows. ([#162058](https://github.com/pytorch/pytorch/pull/162058))
- [inductor] fix test output path 2 ([#162085](https://github.com/pytorch/pytorch/pull/162085))
- [AMD] [Reland] Fix AMD User Defined Kernel Autotune ([#161521](https://github.com/pytorch/pytorch/pull/161521))
- [inductor] Fix int64 from MutationOutput Buffer ([#162020](https://github.com/pytorch/pytorch/pull/162020))
- Apply Triton tensor descriptor for flex-decoding for performance ([#161643](https://github.com/pytorch/pytorch/pull/161643))
- Forward fix for user defined triton kernel grid calc ([#162162](https://github.com/pytorch/pytorch/pull/162162))
- [Inductor][Intel GPU] Register triton template heuristic for addmm tma. ([#162132](https://github.com/pytorch/pytorch/pull/162132))
- Allow for using a dedicated binary for the torch subproc pool. ([#162093](https://github.com/pytorch/pytorch/pull/162093))
- [BE] [Inductor] Add Kernel name to all coor-desc tuning ([#161409](https://github.com/pytorch/pytorch/pull/161409))
- [ez][inductor] add a few outer dimension reduction cases for LOAF ([#162028](https://github.com/pytorch/pytorch/pull/162028))
- [Intel GPU][FlexAttention] Enable TMA path on Intel GPU ([#162138](https://github.com/pytorch/pytorch/pull/162138))
- [inductor][contigous mm] mild refactor ([#162075](https://github.com/pytorch/pytorch/pull/162075))
- [inductor] move scaled_mm input nodes logic ([#161340](https://github.com/pytorch/pytorch/pull/161340))
- [inductor][ez] add template/externchoice uid ([#161341](https://github.com/pytorch/pytorch/pull/161341))
- [inductor][aten] treat like a template in GEMMs ([#161342](https://github.com/pytorch/pytorch/pull/161342))
- [inductor][ez] pass template rather than template.uid ([#161343](https://github.com/pytorch/pytorch/pull/161343))
- [inductor] move max-autotune logic inside V.choices.get_mm_configs ([#161344](https://github.com/pytorch/pytorch/pull/161344))
- [inductor][ez] return choicecallers directly ([#161345](https://github.com/pytorch/pytorch/pull/161345))
- [inductor] V.choice.get_mm_configs takes a stack of templates ([#161346](https://github.com/pytorch/pytorch/pull/161346))
- [Inductor] Improve RoPE ([#161420](https://github.com/pytorch/pytorch/pull/161420))
- allow user to pass in custom partitioner function ([#157580](https://github.com/pytorch/pytorch/pull/157580))
- [inductor] estimate peak memory in codegen only when buffer reuse ([#162300](https://github.com/pytorch/pytorch/pull/162300))
- [inductor] fix TemplateBuffer.extract_read_writes ([#162221](https://github.com/pytorch/pytorch/pull/162221))
- [inductor] rename deps during refreshing ([#162303](https://github.com/pytorch/pytorch/pull/162303))
- [inductor][triton] more JITCallable._hash_lock support ([#162244](https://github.com/pytorch/pytorch/pull/162244))
- [upstream triton] update triton pin to triton 3.5 ([#162278](https://github.com/pytorch/pytorch/pull/162278))
- [inductor] Runtime estimations: use nccl estimator; mm only benchmark mode ([#161405](https://github.com/pytorch/pytorch/pull/161405))
- [refactor] add helper sizevars function, is_size_one, for size==1 checks ([#162189](https://github.com/pytorch/pytorch/pull/162189))
- [inductor] fix 3d tiled online softmax ([#162341](https://github.com/pytorch/pytorch/pull/162341))
### security

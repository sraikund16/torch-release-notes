# Miscategorized commits

Welcome to the Pool of Miscategorized commits.
Add any commits that were miscategorized for your domain below.
Handle any commits that actually do belong to your domain and remove them from this list.

## Untopiced
- [ROCm] Add FP8 rowwise support to _scaled_grouped_mm + Submodule update ([#159075](https://github.com/pytorch/pytorch/pull/159075))
- [CPU] Support GQA for flash attention ([#157893](https://github.com/pytorch/pytorch/pull/157893))
- Improve error message for torch.binomial enforcing float inputs ([#157658](https://github.com/pytorch/pytorch/pull/157658))
- Detach tensor before clone in SGD optimiser and other code ([#159204](https://github.com/pytorch/pytorch/pull/159204))
- Feature: Implement support for `cudnn_batch_norm_out` kernel to replace the autogen approach. ([#123020](https://github.com/pytorch/pytorch/pull/123020))

Serialization:
- Improve error message for weight-only load errors ([#159935](https://github.com/pytorch/pytorch/pull/159935))

## not user facing
- Fix Pandas version mismatch upon reinstalling numpy ([#158584](https://github.com/pytorch/pytorch/pull/158584))
- [CUDA-13] Implement workaround for cudaErrorNotSupported ([#162412](https://github.com/pytorch/pytorch/pull/162412))
- [FP8] FP8 for SwishLayerNorm ([#157574](https://github.com/pytorch/pytorch/pull/157574))
- Add aot_export_joint_with_descriptors and aot_compile_joint_with_descriptors ([#158715](https://github.com/pytorch/pytorch/pull/158715))
- _aot_export_function: allow keeping input mutations in the graph ([#157730](https://github.com/pytorch/pytorch/pull/157730))
- Extract out prepare_aot_module_simplified for use in next PR ([#158319](https://github.com/pytorch/pytorch/pull/158319))
- Rename modules in AOTAutograd ([#158449](https://github.com/pytorch/pytorch/pull/158449))
- Track descriptors for all inputs/outputs of AOTAutograd traced graph ([#158624](https://github.com/pytorch/pytorch/pull/158624))
- Improve graph output alias with subclass error message ([#159619](https://github.com/pytorch/pytorch/pull/159619))
- Pass fw/bw compilers to aot_export_joint_with_descriptors ([#159814](https://github.com/pytorch/pytorch/pull/159814))
- Add support for param mutation under inference mode ([#159661](https://github.com/pytorch/pytorch/pull/159661))
- [PT2]: Add Static Dispatch Kernel for fmod.Scalar ([#160654](https://github.com/pytorch/pytorch/pull/160654))
- [PT2]: Add Static Dispatch Kernel for scale_gradient ([#160454](https://github.com/pytorch/pytorch/pull/160454))
- [DCP][Quantization] Fix for FP8 multiplication during dequantization ([#162202](https://github.com/pytorch/pytorch/pull/162202))
- [DCP][Quantization] Fix the issue when scale vector is in a different SafeTensors file ([#162214](https://github.com/pytorch/pytorch/pull/162214))
